import streamlit as st
import requests
import pandas as pd
import io
from datetime import datetime
import pytz

JST = pytz.timezone("Asia/Tokyo")

HEADERS = {"User-Agent": "Mozilla/5.0"}

# --- æ–°: ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°å–å¾—API ---
def fetch_event_detail(event_id, room_id):
    url = f"https://www.showroom-live.com/api/event/contribution_ranking?event_id={event_id}&room_id={room_id}"
    try:
        res = requests.get(url, headers=HEADERS, timeout=10)
        if res.status_code != 200:
            return {}
        data = res.json()
        ev = data.get("event", {})
        if not ev:
            return {}
        return {
            "event_name": ev.get("event_name"),
            "started_at": datetime.fromtimestamp(ev.get("started_at"), JST).strftime("%Y/%m/%d %H:%M"),
            "ended_at": datetime.fromtimestamp(ev.get("ended_at"), JST).strftime("%Y/%m/%d %H:%M"),
            "event_url": ev.get("event_url"),
            "event_image": ev.get("image")
        }
    except Exception:
        return {}

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def fetch_and_merge_event_data():
    # ä¾‹: ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦å›ºå®šãƒ«ãƒ¼ãƒ ãƒªã‚¹ãƒˆï¼ˆæœ¬æ¥ã¯room_list.csvã‚’å‚ç…§ï¼‰
    managed_rooms = pd.read_csv("https://mksoul-pro.com/showroom/file/room_list.csv", dtype=str)

    records = []

    # ä»®: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã® event_id ã‚’å›ºå®š
    EVENT_ID_START, EVENT_ID_END = 40291, 40292

    for event_id in range(EVENT_ID_START, EVENT_ID_END + 1):
        for _, row in managed_rooms.iterrows():
            rid = row["ãƒ«ãƒ¼ãƒ ID"]
            account_id = row["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID"]
            room_name = row["ãƒ«ãƒ¼ãƒ å"]

            # --- ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ã‚’å–å¾— ---
            detail = fetch_event_detail(event_id, rid)
            if not detail:
                continue  # å‚åŠ ã—ã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

            # ä»®: é †ä½ã‚„ãƒã‚¤ãƒ³ãƒˆã¯ API(room_list) ã‹ã‚‰å–å¾—ã™ã‚‹ã®ãŒæœ¬ç­‹
            # ä»Šå›ã¯ãƒ€ãƒŸãƒ¼ï¼ˆ0ï¼‰ã§åŸ‹ã‚ã¦ãŠã
            rank = 0
            point = 0
            level = 0

            records.append({
                "PRå¯¾è±¡": "",
                "ãƒ©ã‚¤ãƒãƒ¼å": room_name,
                "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID": account_id,
                "ã‚¤ãƒ™ãƒ³ãƒˆå": detail.get("event_name"),
                "é–‹å§‹æ—¥æ™‚": detail.get("started_at"),
                "çµ‚äº†æ—¥æ™‚": detail.get("ended_at"),
                "é †ä½": rank,
                "ãƒã‚¤ãƒ³ãƒˆ": point,
                "ç´ä»˜ã‘": "â—‹",
                "URL": detail.get("event_url"),
                "ãƒ¬ãƒ™ãƒ«": level,
                "event_id": str(event_id),
                "ãƒ«ãƒ¼ãƒ ID": rid,
                "ã‚¤ãƒ™ãƒ³ãƒˆç”»åƒï¼ˆURLï¼‰": detail.get("event_image")
            })

    df = pd.DataFrame(records)
    return df

# --- Streamlit UI ---
def main():
    st.title("ğŸ¯ SHOWROOM ã‚¤ãƒ™ãƒ³ãƒˆå‚åŠ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°")

    df = fetch_and_merge_event_data()

    if df.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    st.success("âœ… ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
    st.dataframe(df)

    # CSVå‡ºåŠ›
    csv_bytes = df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes, file_name="event_database.csv", mime="text/csv")

if __name__ == "__main__":
    main()
